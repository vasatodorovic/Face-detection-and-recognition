{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPEWLu5Cl3tgUJRvKiPSIHm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZiBvnTMKYWo",
        "outputId": "d48df631-19a5-4012-b9dc-23f396c07040"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install torch torchvision opencv-python"
      ],
      "metadata": {
        "id": "Ehw9rP59MCXp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split"
      ],
      "metadata": {
        "id": "SUb3PqAxMzMn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FaceDataset(Dataset):\n",
        "  def __init__(self,img_dir,label_dir,img_size=448,transform=None):\n",
        "    self.img_dir = img_dir\n",
        "    self.label_dir = label_dir\n",
        "    self.img_size=img_size\n",
        "    self.transform = transform\n",
        "    self.img_files = [f for f in os.listdir(img_dir) if f.endswith('.jpg')]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_files)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    img_path = os.path.join(self.img_dir,self.img_files[idx])\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    img = img.resize((self.img_size,self.img_size))\n",
        "\n",
        "    label_path = os.path.join(self.label_dir,self.img_files[idx].replace('.jpg', '.txt'))\n",
        "    boxes = []\n",
        "\n",
        "    if os.path.exists(label_path):\n",
        "      with open(label_path,'r') as file:\n",
        "        for line in file:\n",
        "          class_id, x_center, y_center, width, height = map(float, line.split())\n",
        "          x_center *= self.img_size\n",
        "          y_center *= self.img_size\n",
        "          width *= self.img_size\n",
        "          height *= self.img_size\n",
        "\n",
        "          x_min = x_center - width / 2\n",
        "          y_min = y_center - height / 2\n",
        "          x_max = x_center + width / 2\n",
        "          y_max = y_center + height / 2\n",
        "          boxes.append([x_min, y_min, x_max, y_max, int(class_id)])\n",
        "\n",
        "    boxes = np.array(boxes)\n",
        "\n",
        "    if self.transform:\n",
        "      img = self.transform(img)\n",
        "\n",
        "    return img, boxes"
      ],
      "metadata": {
        "id": "jsFEO-uIPDmp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "img_dir_train=None\n",
        "label_dir_train=None\n",
        "img_dir_test=None\n",
        "label_dir_test=None\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_val_dataset = FaceDataset(\n",
        "    img_dir=img_dir_train,\n",
        "    label_dir=label_dir_train,\n",
        "    transform=data_transforms\n",
        ")\n",
        "\n",
        "test_dataset = FaceDataset(\n",
        "    img_dir=img_dir_test,\n",
        "    label_dir=label_dir_test,\n",
        "    transform=data_transforms\n",
        ")\n",
        "\n",
        "train_size = int(0.8 * len(train_val_dataset))\n",
        "val_size = len(train_val_dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(train_val_dataset, [train_size, val_size])"
      ],
      "metadata": {
        "id": "LoHOLTeMWRF7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TUlIemRmesdl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
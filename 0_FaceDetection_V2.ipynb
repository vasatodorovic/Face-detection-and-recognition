{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPIpnQM3itErm7NZhW+dI48"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "coBUNp4UXKlZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5eaa21a-00d1-407e-c29d-edc4d874bbdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "LNA2nLtkX91J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4762bb2e-5178-4102-9cbe-a99e583888fe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split"
      ],
      "metadata": {
        "id": "kg5GtSJfX_Tf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FaceDataset(Dataset):\n",
        "    def __init__(self, img_dir, label_dir, img_size=448, grid_size=14, num_bboxes=1, max_images=None, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.label_dir = label_dir\n",
        "        self.img_size = img_size\n",
        "        self.grid_size = grid_size\n",
        "        self.num_bboxes = num_bboxes\n",
        "        self.transform = transform\n",
        "        self.img_files = []\n",
        "        count = 0\n",
        "        for img_file in os.listdir(img_dir):\n",
        "            if img_file.endswith('.jpg'):\n",
        "                self.img_files.append(img_file)\n",
        "                count += 1\n",
        "                if max_images is not None and count >= max_images:\n",
        "                    break\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_files[idx])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        img = img.resize((self.img_size, self.img_size))\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        label_path = os.path.join(self.label_dir, self.img_files[idx].replace('.jpg', '.txt'))\n",
        "        boxes = []\n",
        "\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, 'r') as file:\n",
        "                for line in file:\n",
        "                    _, x_center, y_center, width, height = map(float, line.strip().split())\n",
        "                    boxes.append([x_center, y_center, width, height, 1.0])\n",
        "\n",
        "        target_grid = self.map_targets_to_grid(boxes, self.grid_size, self.num_bboxes)\n",
        "\n",
        "        return img, target_grid\n",
        "\n",
        "    def map_targets_to_grid(self, targets, grid_size, num_bboxes):\n",
        "        target_grid = torch.zeros((grid_size, grid_size, num_bboxes * 5))\n",
        "\n",
        "        for target in targets:\n",
        "            x_center, y_center, width, height, conf = target\n",
        "            #print('-------------------------------------')\n",
        "            #print(x_center, y_center, width, height, conf)\n",
        "            grid_x = int(x_center * grid_size)\n",
        "            grid_y = int(y_center * grid_size)\n",
        "\n",
        "            x_center = (x_center * grid_size) - grid_x\n",
        "            y_center = (y_center * grid_size) - grid_y\n",
        "            #print(x_center, y_center, width, height, conf)\n",
        "            bbox_index = 0\n",
        "            target_grid[grid_y, grid_x, bbox_index * 5:bbox_index * 5 + 4] = torch.tensor([x_center, y_center, width, height])\n",
        "            target_grid[grid_y, grid_x, bbox_index * 5 + 4] = conf\n",
        "\n",
        "        return target_grid\n"
      ],
      "metadata": {
        "id": "fY0RtJ7_YA6t"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_dir_train='/content/drive/My Drive/YoloData/images/train'\n",
        "label_dir_train='/content/drive/My Drive/YoloData/labels/train'\n",
        "img_dir_test='/content/drive/My Drive/YoloData/images/val'\n",
        "label_dir_test='/content/drive/My Drive/YoloData/labels/val'\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_val_dataset = FaceDataset(\n",
        "    img_dir=img_dir_train,\n",
        "    label_dir=label_dir_train,\n",
        "    transform=data_transforms,\n",
        "    max_images=5000\n",
        ")\n",
        "train_size = int(0.8 * len(train_val_dataset))\n",
        "val_size = len(train_val_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(train_val_dataset, [train_size, val_size])\n",
        "\n",
        "test_dataset = FaceDataset(\n",
        "    img_dir=img_dir_test,\n",
        "    label_dir=label_dir_test,\n",
        "    transform=data_transforms,\n",
        "    max_images=1000\n",
        ")"
      ],
      "metadata": {
        "id": "_DHyoglPYmgg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    images, targets = zip(*batch)\n",
        "\n",
        "    images = torch.stack(images, dim=0)\n",
        "\n",
        "    return images, targets"
      ],
      "metadata": {
        "id": "FRECGwl9YpwH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2,collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset,batch_size=16,shuffle=True,num_workers=2,collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2,collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "Pa5c681aYrnx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_dataset[0]"
      ],
      "metadata": {
        "id": "xwbA78XhgsbP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Q22AdSptYsHx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class YOLO(nn.Module):\n",
        "  def __init__(self,grid_size=14,num_bboxes=1):\n",
        "    super(YOLO,self).__init__()\n",
        "    self.grid_size=grid_size\n",
        "    self.num_bboxes=num_bboxes\n",
        "    self.num_classes=1\n",
        "\n",
        "    self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 192, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(192),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(192, 128, kernel_size=1, stride=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.1),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.1),\n",
        "\n",
        "            nn.Conv2d(256, 256, kernel_size=1, stride=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2) #14x14x512\n",
        "        )\n",
        "\n",
        "    self.fc_layers = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512 * self.grid_size * self.grid_size, 4096),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Linear(4096, self.grid_size * self.grid_size * (self.num_bboxes * 5))\n",
        "        )\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "        x = self.conv_layers(x)\n",
        "        x = self.fc_layers(x)\n",
        "\n",
        "        x = x.view(-1, self.grid_size, self.grid_size, self.num_bboxes * 5)\n",
        "\n",
        "        bboxes = torch.sigmoid(x[..., :self.num_bboxes * 5])\n",
        "\n",
        "        return bboxes\n",
        "  def predict(self, x, iou_threshold=0.5, confidence_threshold=0.5):\n",
        "        bboxes = self.forward(x)\n",
        "\n",
        "        filtered_boxes = []\n",
        "        filtered_scores = []\n",
        "\n",
        "\n",
        "        for i in range(self.grid_size):\n",
        "            for j in range(self.grid_size):\n",
        "                for b in range(self.num_bboxes):\n",
        "                    offset = b * 5\n",
        "                    confidence = bboxes[:, i, j, offset + 4]\n",
        "                    if confidence > confidence_threshold:\n",
        "                        box = bboxes[:, i, j, offset:offset + 4]\n",
        "                        score = confidence\n",
        "                        filtered_boxes.append(box)\n",
        "                        filtered_scores.append(score)\n",
        "\n",
        "\n",
        "        if len(filtered_boxes) == 0:\n",
        "            return [], []\n",
        "\n",
        "        filtered_boxes = torch.stack(filtered_boxes)\n",
        "        filtered_scores = torch.stack(filtered_scores)\n",
        "\n",
        "\n",
        "        keep_indices = nms(filtered_boxes, filtered_scores, iou_threshold)\n",
        "        final_boxes = filtered_boxes[keep_indices]\n",
        "        final_scores = filtered_scores[keep_indices]\n",
        "\n",
        "\n",
        "        return final_boxes, final_scores\n"
      ],
      "metadata": {
        "id": "ZeGA9HJEYubL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def xywh_to_xyxy(box):\n",
        "    x_center, y_center, width, height = box[..., 0], box[..., 1], box[..., 2], box[..., 3]\n",
        "    x_min = x_center - width / 2\n",
        "    y_min = y_center - height / 2\n",
        "    x_max = x_center + width / 2\n",
        "    y_max = y_center + height / 2\n",
        "    return torch.stack([x_min, y_min, x_max, y_max], dim=-1)"
      ],
      "metadata": {
        "id": "6gsDdSyFZg2y"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def iou(boxes1, boxes2):\n",
        "    boxes1 = xywh_to_xyxy(boxes1)\n",
        "    boxes2 = xywh_to_xyxy(boxes2)\n",
        "\n",
        "    inter_x_min = torch.max(boxes1[..., 0], boxes2[..., 0])\n",
        "    inter_y_min = torch.max(boxes1[..., 1], boxes2[..., 1])\n",
        "    inter_x_max = torch.min(boxes1[..., 2], boxes2[..., 2])\n",
        "    inter_y_max = torch.min(boxes1[..., 3], boxes2[..., 3])\n",
        "\n",
        "    inter_area = torch.clamp(inter_x_max - inter_x_min, min=0) * torch.clamp(inter_y_max - inter_y_min, min=0)\n",
        "\n",
        "    area1 = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
        "    area2 = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
        "\n",
        "    union_area = area1 + area2 - inter_area\n",
        "    iou = inter_area / torch.clamp(union_area, min=1e-6)\n",
        "\n",
        "    return iou"
      ],
      "metadata": {
        "id": "nhBNWmLgZjZF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nms(bboxes, scores, iou_threshold=0.5):\n",
        "    keep = []\n",
        "    indices = scores.sort(descending=True)[1]\n",
        "\n",
        "    while indices.numel() > 0:\n",
        "        current = indices[0]\n",
        "        keep.append(current.item())\n",
        "        if indices.numel() == 1:\n",
        "            break\n",
        "\n",
        "        ious = iou(bboxes[current], bboxes[indices[1:]])\n",
        "        indices = indices[1:][ious < iou_threshold]\n",
        "\n",
        "    return keep"
      ],
      "metadata": {
        "id": "gatmx3u-Zk7G"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def yolo_loss(pred_bboxes, target, lambda_coord=5,lambda_size=5,lambda_obj=1, lambda_noobj=0.5):\n",
        "    obj_mask = target[..., 4] > 0\n",
        "    noobj_mask = target[..., 4] == 0\n",
        "\n",
        "    coord_center_loss = lambda_coord * torch.sum((pred_bboxes[obj_mask][..., :2] - target[obj_mask][..., :2]) ** 2)\n",
        "    coord_size_loss = lambda_size * torch.sum(pred_bboxes[obj_mask][..., 2:4] - target[obj_mask][..., 2:4] ** 2)\n",
        "\n",
        "    iou_scores = iou(pred_bboxes[obj_mask][..., :4], target[obj_mask][..., :4])\n",
        "\n",
        "    obj_loss = lambda_obj*torch.sum((iou_scores-pred_bboxes[obj_mask][..., 4]) ** 2)\n",
        "    noobj_loss = lambda_noobj * torch.sum(target[noobj_mask][..., 4]** 2)\n",
        "    #noobj_loss_1 = lambda_noobj * torch.sum(torch.clamp(pred_bboxes[noobj_mask_1][..., 4], min=1e-6) ** 2)\n",
        "\n",
        "    loss = coord_center_loss + coord_size_loss + obj_loss + noobj_loss\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "9nnr5xB-ZxkG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdDnsuBPjBrY",
        "outputId": "40f745fd-8945-47ab-cd9a-4bf1b0d02894"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "YOLO(\n",
              "  (conv_layers): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (5): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): LeakyReLU(negative_slope=0.1)\n",
              "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (8): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): LeakyReLU(negative_slope=0.1)\n",
              "    (11): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (13): LeakyReLU(negative_slope=0.1)\n",
              "    (14): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (16): LeakyReLU(negative_slope=0.1)\n",
              "    (17): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (18): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (20): LeakyReLU(negative_slope=0.1)\n",
              "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc_layers): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=100352, out_features=4096, bias=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Linear(in_features=4096, out_features=980, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "\n",
        "def train_model(model, train_loader, val_loader, num_epochs=10, learning_rate=0.0001,checkpoint_dir='/content/drive/My Drive/checkpoints',patience=5):\n",
        "    training_losses = []\n",
        "    validation_losses = []\n",
        "    best_val_loss = np.inf\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate,weight_decay=0.0005)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
        "\n",
        "        for images, targets in progress_bar:\n",
        "            images = images.to(device)\n",
        "\n",
        "            targets = [target.to(device) for target in targets]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            bboxes = model(images) #(8,14,14,5)\n",
        "\n",
        "            losses = [yolo_loss(bbox, target) for bbox, target in zip(bboxes, targets)]\n",
        "            loss = torch.mean(torch.stack(losses))\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            progress_bar.set_postfix({'Loss': loss.item()})\n",
        "\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        training_losses.append(avg_loss)\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss}\")\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        model.eval()\n",
        "        val_running_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for val_images, val_targets in val_loader:\n",
        "                val_images = val_images.to(device)\n",
        "                val_targets = [val_target.to(device) for val_target in val_targets]\n",
        "\n",
        "                val_bboxes = model(val_images)\n",
        "                val_losses = [yolo_loss(val_bbox, val_target) for val_bbox, val_target in zip(val_bboxes, val_targets)]\n",
        "                val_loss = torch.mean(torch.stack(val_losses))\n",
        "\n",
        "                val_running_loss += val_loss.item()\n",
        "\n",
        "        avg_val_loss = val_running_loss / len(val_loader)\n",
        "        validation_losses.append(avg_val_loss)\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {avg_val_loss}\")\n",
        "        if((epoch+1)%2==0):\n",
        "          save_checkpoint(model, optimizer, epoch + 1, avg_loss, checkpoint_dir)\n",
        "        model.train()\n",
        "\n",
        "    print(\"Training complete!\")\n",
        "    return training_losses,validation_losses\n"
      ],
      "metadata": {
        "id": "996DovKkZyFj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(model, optimizer, epoch, loss, checkpoint_dir=\"checkpoints\"):\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, f\"V2_model_epoch_{epoch}_loss_{loss:.4f}.pth\")\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss,\n",
        "    }, checkpoint_path)\n",
        "    print(f\"Checkpoint saved at {checkpoint_path}\")"
      ],
      "metadata": {
        "id": "4EhImPyFZz-u"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_checkpoint(checkpoint_path, model, optimizer):\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch = checkpoint['epoch']\n",
        "    loss = checkpoint['loss']\n",
        "    print(f\"Loaded checkpoint '{checkpoint_path}' (epoch {epoch}, loss {loss})\")\n",
        "    return epoch, loss"
      ],
      "metadata": {
        "id": "PcmiKN8mZ2Z5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "def predict_and_draw(model, test_loader, device):\n",
        "    model.eval()\n",
        "\n",
        "    data_iter = iter(test_loader)\n",
        "    next(data_iter)\n",
        "    next(data_iter)\n",
        "    next(data_iter)\n",
        "    next(data_iter)\n",
        "    #next(data_iter)\n",
        "    images, targets = next(data_iter)\n",
        "    image = images[0].unsqueeze(0).to(device)\n",
        "    print(\"Image size:\", image.shape)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        predictions = model(image)\n",
        "\n",
        "    predictions = predictions[0].cpu().numpy()\n",
        "\n",
        "    img = images[0].permute(1, 2, 0).cpu().numpy()\n",
        "    plt.imshow(img)\n",
        "    ax = plt.gca()\n",
        "\n",
        "    grid_size = 14\n",
        "    num_bboxes = 1\n",
        "\n",
        "    for i in range(grid_size):\n",
        "        for j in range(grid_size):\n",
        "            confidence = predictions[i, j, 4]\n",
        "            if confidence > 0:\n",
        "                x_center, y_center, width, height = predictions[i, j, :4]\n",
        "                print(f\"Box: {i},{j}\")\n",
        "                print(x_center, y_center, width, height, confidence)\n",
        "\n",
        "\n",
        "                x_center = (x_center + j) / grid_size\n",
        "                y_center = (y_center + i) / grid_size\n",
        "\n",
        "\n",
        "                width /= grid_size\n",
        "                height /= grid_size\n",
        "\n",
        "                xmin = x_center - width / 2\n",
        "                ymin = y_center - height / 2\n",
        "                xmax = x_center + width / 2\n",
        "                ymax = y_center + height / 2\n",
        "\n",
        "\n",
        "                xmin *= img.shape[1]\n",
        "                xmax *= img.shape[1]\n",
        "                ymin *= img.shape[0]\n",
        "                ymax *= img.shape[0]\n",
        "\n",
        "                rect = plt.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, fill=False, color='red')\n",
        "                ax.add_patch(rect)\n",
        "\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "Rm2VMsoEZ4hi"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_losses,validation_losses = train_model(model,train_loader,val_loader,num_epochs=35)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5YWMd1Hit7f",
        "outputId": "da3bdf1b-1d47-4c80-ec74-91d95736cecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [1/35]: 100%|██████████| 250/250 [33:50<00:00,  8.12s/it, Loss=7.13]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/35], Loss: 8.851869491577148\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/35], Validation Loss: 9.170057803865463\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [2/35]: 100%|██████████| 250/250 [02:24<00:00,  1.73it/s, Loss=4.4]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/35], Loss: 8.386895565032958\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/35], Validation Loss: 9.192597192431252\n",
            "Checkpoint saved at /content/drive/My Drive/checkpoints/V2_model_epoch_2_loss_8.3869.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [3/35]: 100%|██████████| 250/250 [02:43<00:00,  1.53it/s, Loss=9.07]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/35], Loss: 8.323365762710571\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/35], Validation Loss: 9.24989900891743\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [4/35]: 100%|██████████| 250/250 [02:21<00:00,  1.77it/s, Loss=7.64]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/35], Loss: 8.493031445503235\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/35], Validation Loss: 9.53250972051469\n",
            "Checkpoint saved at /content/drive/My Drive/checkpoints/V2_model_epoch_4_loss_8.4930.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [5/35]: 100%|██████████| 250/250 [02:41<00:00,  1.55it/s, Loss=6.37]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/35], Loss: 8.494858006477356\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/35], Validation Loss: 9.578392452663845\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [6/35]: 100%|██████████| 250/250 [02:22<00:00,  1.76it/s, Loss=12]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/35], Loss: 8.513794486045837\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/35], Validation Loss: 9.525426183428083\n",
            "Checkpoint saved at /content/drive/My Drive/checkpoints/V2_model_epoch_6_loss_8.5138.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [7/35]: 100%|██████████| 250/250 [02:47<00:00,  1.49it/s, Loss=6.64]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/35], Loss: 8.438693099975586\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/35], Validation Loss: 9.323019958677746\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [8/35]: 100%|██████████| 250/250 [02:20<00:00,  1.78it/s, Loss=8.8]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/35], Loss: 8.415054872512817\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/35], Validation Loss: 9.418920214214022\n",
            "Checkpoint saved at /content/drive/My Drive/checkpoints/V2_model_epoch_8_loss_8.4151.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [9/35]: 100%|██████████| 250/250 [02:48<00:00,  1.49it/s, Loss=12]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/35], Loss: 8.404593872070313\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/35], Validation Loss: 9.49513268092322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [10/35]: 100%|██████████| 250/250 [02:21<00:00,  1.77it/s, Loss=6.23]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/35], Loss: 8.38321106338501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/35], Validation Loss: 9.466433464534699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7jI9-5HMkDiO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}